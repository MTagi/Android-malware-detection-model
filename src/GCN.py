
from dgl.nn import GraphConv
import torch.nn.functional as F
import torch
from torch import Tensor
from torch_geometric.utils.convert import to_networkx, from_networkx
import pandas as pd
from sklearn.model_selection import train_test_split
import os
import networkx as nx
import dgl
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.ensemble import RandomForestClassifier
import pickle
from sklearn.model_selection import GridSearchCV
# Thực hiện gán nhãn cho dữ liệu
def readData(path: str):
  dic = {
      "filename": [],
      "label": []
  }
  for label in ["khongdoc", "doc"]:
    for file in os.listdir(path + "/" + label):
      if file.endswith(".fcg"):
        dic['filename'].append("/".join([path, label, file]))
        dic['label'].append(0 if label == "khongdoc" else 1)
  df = pd.DataFrame(dic)
  return df
def loadGraph(filename: list):
  g = dgl.load_graphs(filename)
  return g[0][0]
class GCN(nn.Module, object):
  def __init__(self, infeats, h1feats, h2feats, h3feats, fc_layer, outclass):
    super(GCN, self).__init__()
    self.conv1 = GraphConv(infeats, h1feats)
    self.conv2 = GraphConv(h1feats, h2feats)
    self.conv3 = GraphConv(h2feats, h3feats)
    self.fc1 = nn.Linear(h3feats, fc_layer)
    self.fc2 = nn.Linear(fc_layer, outclass)

    nn.init.xavier_uniform(self.fc1.weight)
    nn.init.xavier_uniform(self.fc2.weight)

  def g2v(self, g, infeats):
    g = dgl.add_self_loop(g)
    h = self.conv1(g, infeats)
    h = F.relu(h)
    h = self.conv2(g, h)
    h = F.relu(h)
    h = self.conv3(g, h)
    h = F.relu(h)
    g.ndata['thuoctinh'] = h
    h = dgl.mean_nodes(g, 'thuoctinh')
    ans = self.fc1(h)
    ans = F.relu(ans)
    ans = self.fc2(ans)
    return ans, h

  def forward(self, gs: list[dgl.DGLGraph]):
    lg = []
    for g in gs:
      lg.append(self.g2v(g, g.ndata["thuoctinh"])[0].float())
    ans = torch.cat(lg, dim=0)
    return ans

  def vecgen(self, gs: list[dgl.DGLGraph]):
    lg = []
    for g in gs:
      lg.append(self.g2v(g, g.ndata["thuoctinh"])[1].float())
    ans = torch.cat(lg, dim=0)
    return ans

  def save(self, path):
    torch.save(self.state_dict(), path)

  def load(self, path):
    self.load_state_dict(torch.load(path))
def getTupMap(df: pd.DataFrame):
   mp = [(i, gp) for i, gp in enumerate(list(df['filename']))]

   return mp
def createBatch(idx_batch: Tensor, mapping: dict):
  return [loadGraph(mapping[idx]) for idx in idx_batch.tolist()]
def train(nepoch, nbatch):
    df = readData("/content/drive/MyDrive/data")
    X_train, X_test, y_train, y_test = train_test_split(df.drop(['label'], axis=1), df['label'], test_size=0.3, random_state=42)

    model = GCN(infeats=384, h1feats=100, h2feats=100, h3feats=60, fc_layer=32, outclass=2)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)
    criterion = torch.nn.CrossEntropyLoss()

    tupmap = getTupMap(X_train)
    # Change list of tuples (idx, graph) to a dict of {idx:graph}
    mapping = dict(tupmap)
    dataset = TensorDataset(Tensor(list(zip(*tupmap))[0]).long(),Tensor(list(y_train)).long())
    tupbatches = DataLoader(dataset=dataset, batch_size=nbatch, shuffle=True)
    result = {
        "loss":[],
        "epoch": []
    }
    for epoch in (range(nepoch)):
      tmp =iter(tupbatches)
      for i in tqdm(range(len(tupbatches))):
        idx_batch, label_batch = next(tmp)
        bg = createBatch(idx_batch, mapping)
        model.train()
        pred_batch = model(bg)
        loss = criterion(pred_batch, label_batch)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
      result['loss'].append(loss.item())
      result['epoch'].append(epoch)
      if epoch % 1 == 0:

        print("epoch:", epoch, "   loss:", loss.item())
        model.save(f"/content/drive/MyDrive/weight/model_{str(epoch).zfill(2)}.pt")
        model.eval()
        with torch.no_grad():
          tumap = getTupMap(X_test)
          maping = dict(tumap)
          dataset_Test = TensorDataset(Tensor(list(zip(*tumap))[0]).long(), Tensor(list(y_test)).long())
          tupleb= DataLoader(dataset=dataset_Test, batch_size=150, shuffle=True)
          for a, b in tupleb:
            graphs = createBatch(a, maping)
            out = model(graphs)
            pred = out.argmax(dim=1).long()
            print(f'Test Accuracy: {accuracy_score(pred, b):.4f}')

train(nepoch=40, nbatch=32)